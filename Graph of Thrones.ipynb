{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base imports\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# Classifier imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph of Thrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a dataset containing the characters that appear in G.R.R Martin's epic fantasy series *A Song of Ice and Fire*. Can we predict who lives and dies in the first book based on a character's Allegiance, Gender, Nobility and the chapter in which they are introduced? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of characters from the first book, print the first 5\n",
    "characters =[]\n",
    "with open('data/asoiaf-book1-nodes.csv') as f: [characters.append(line.split(',')[1].strip()) for line in f]\n",
    "characters.pop(0) # pop out the label\n",
    "characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data regarding deaths\n",
    "death_df = pd.read_csv('data/character-deaths.csv')\n",
    "death_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "death_df['Dead'] = death_df['Death Year'].apply(lambda x: 1 if x==x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare count of Characters in each set\n",
    "print(f\"\"\"Total Characters: {len(death_df)}, First Book Characters: {len(death_df.query(f'Name in {characters}'))}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab death data from Characters in the first book\n",
    "first_deaths = death_df.query(f'Name in {characters}').reset_index(drop=True)\n",
    "first_deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab relevant features and one hot encode categorical data (Allegiances)\n",
    "features = ['Name','Book Intro Chapter','Gender','Nobility','Dead']\n",
    "df=pd.concat([first_deaths[features],pd.get_dummies(first_deaths['Allegiances'], prefix='allegiance',drop_first=True)],axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the balance of our target class\n",
    "plt.bar(['Not Dead','Dead'],df.Dead.value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Death\n",
    "\n",
    "### Tabular Data\n",
    ">*Valar Morghulis* (All Men must die) -- A Clash of Kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a collection of classifiers\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Random Forest\", \"Neural Net\",\"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=3,random_state=42),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    LogisticRegression(solver='liblinear', random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X, y = df.drop(['Name','Dead'],axis=1), df['Dead']\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Untuned classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'Base F1 Score for {name}: {f1_score(y_test, clf.predict(X_test)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have some baseline scores for models built solely on tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Data\n",
    ">Every Man must die, but first He must live. -- Storm of Swords\n",
    "\n",
    "Let's see if we can capture more information about these characters based on their interactions with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import graph database\n",
    "book1_df = pd.read_csv('data/asoiaf-book1-edges.csv')\n",
    "G1 = nx.Graph()\n",
    "for row in book1_df.iterrows():\n",
    "    G1.add_edge(row[1]['Source'].replace('-',' '), row[1]['Target'].replace('-',' '), weight=row[1]['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA\n",
    "What information do the edge weights capture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect relationship/edge\n",
    "G1.get_edge_data('Tyrion Lannister','Jon Snow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a network with characters as **Nodes** connected by **Weighted Edges** where the weight corresponds to the amount of dialogue exchanged with each other in the first book. Is this directed or undirected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample of the graph\n",
    "plt.figure(figsize=(12,12))\n",
    "nx.draw(G1.subgraph(df.sample(n=50, random_state=42).Name), with_labels=True, font_weight='bold', pos=nx.spring_layout(G1))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the distribution of weights on the edges look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wts=[]\n",
    "relationships=[]\n",
    "# Loop through each node and its adjacent nodes and capture its weight \n",
    "for n, nbrs in G1.adj.items():\n",
    "    for nbr, eattr in nbrs.items():\n",
    "        wt = eattr['weight']\n",
    "        wts.append(wt)\n",
    "        relationships.append((wt,n,nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine weighted relationship, skip every other one (undirected relationship)\n",
    "print(sorted(relationships,key=(lambda x: x[0]),reverse=True)[:10:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of weights\n",
    "plt.hist(wts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Algorithms\n",
    "\n",
    "Using Graph Theory, let us create some metrics from our network to augment the tabular data used in the models earlier.\n",
    "\n",
    "#### Degree (number of connections normalized by number of possible connections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree and assign it to each node\n",
    "for name, degree in nx.degree_centrality(G1).items():\n",
    "    G1.nodes[name]['degree']=degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Tyrion Lannister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Hosteen Frey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label propagation (community detection algorithm akin to KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign community label to each node in the community and print out the communities\n",
    "communities=[]\n",
    "for label, community in enumerate(nx.algorithms.community.label_propagation.label_propagation_communities(G1)):\n",
    "    communities.append(community)\n",
    "    print(f'Community {label}: {community}')\n",
    "    for name in community:\n",
    "        G1.nodes[name]['community'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these communities tell us about the underlying data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign betweenness metric\n",
    "for name, betweenness in nx.betweenness_centrality(G1, weight='weight', seed=42).items():\n",
    "    G1.nodes[name]['betweenness']=betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Tyrion Lannister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Hosteen Frey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the betweenness tell us about these two characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign pagerank\n",
    "for name, rank in nx.pagerank(G1, weight='weight').items():\n",
    "    G1.nodes[name]['rank']=rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Tyrion Lannister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.nodes['Hosteen Frey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the pagerank tell us about these two characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to augment table data\n",
    "def graph_of_thrones(name):\n",
    "    if G1.nodes[name]:\n",
    "        return [G1.nodes[name]['betweenness'], G1.nodes[name]['community'], G1.nodes[name]['rank'], G1.nodes[name]['degree']]\n",
    "    return [None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add metrics to original DataFrame\n",
    "graph_df = pd.concat([df,pd.DataFrame(df.apply(lambda x: graph_of_thrones(x.Name),axis=1).values.tolist(),columns=['Betweenness','Community','Rank','Degree'])],axis=1)\n",
    "graph_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical feature\n",
    "augmented_df=pd.concat([graph_df.drop('Community',axis=1),pd.get_dummies(graph_df['Community'], prefix='community',drop_first=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect remaining columns\n",
    "augmented_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data \n",
    "X, y = augmented_df.drop(['Name','Dead'],axis=1), augmented_df['Dead']\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "GX_train, GX_test, Gy_train, Gy_test = \\\n",
    "        train_test_split(X, y, test_size=.2, random_state=42)\n",
    "g_scaler = StandardScaler()\n",
    "GX_train = g_scaler.fit_transform(GX_train)\n",
    "GX_test = g_scaler.transform(GX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Untuned Classifiers with number of interactions as weight\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'Base F1 Score for {name}: {f1_score(y_test, clf.predict(X_test))}')\n",
    "    clf.fit(GX_train, Gy_train)\n",
    "    print(f'Graph Augmented F1 Score for {name}: {f1_score(Gy_test, clf.predict(GX_test))} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "We can see an improvement in some of the models but a drop in others. Consider how we set up our network with weighted connections; each edge had the number of interactions between the two characters. How do the models think of the weights for their algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above process has been automated into a pipeline to compare results\n",
    "from helpers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Untuned Classifiers with number of interactions as weights\n",
    "pipeline(df, names, classifiers, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Untuned Classifiers with no weights\n",
    "pipeline(df, names, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuned Classifiers with reciprocal number of interactions as weight\n",
    "pipeline(df, names, classifiers, weight='inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Graph networks and algorithms are a powerful tool to explore the relationships between objects in our data. Networks can be used not only to visualize data but also to create new features that can be useful for machine learning. It is not the solution to every problem, and there is no guarantee that every class of model will be improved by including this type of data. Like any other type of data it is important to explore your features and examine your assumptions.\n",
    "> It is one thing to be **clever** and another to be **wise**. -- A Game of Thrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
